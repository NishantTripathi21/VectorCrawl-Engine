# ğŸ” RAG-Based Search Engine for Any Website
A powerful **Retrieval-Augmented Generation (RAG)** engine that allows users to chat with any website. The system crawls a URL, processes the content into vector embeddings, stores them in Pinecone, and uses **Google Gemini Flash** to answer questions with zero hallucinations.

---

## ğŸš€ Overview

This project transforms static websites into interactive knowledge bases. The backend pipeline performs the following:
1.  **Crawls** the target website (BFS traversal).
2.  **Extracts & Cleans** HTML text (removing ads, scripts, and styles).
3.  **Chunks** content into semantic segments.
4.  **Embeds** text using **Jina AI**.
5.  **Stores** vectors in **Pinecone**.
6.  **Retrieves** context and answers user queries via **Google Gemini Flash**.

---

## âœ¨ Features

### ğŸ•·ï¸ Website Crawler
* **BFS Strategy:** Crawls internal links systematically.
* **Smart Extraction:** Uses Cheerio to strip unnecessary tags (scripts, styles, ads).
* **Safety:** Handles infinite loops and duplicate pages.

### âœ‚ï¸ Intelligent Processing
* **Text Chunking:** Splits content into 500â€“1000 token segments while preserving semantic meaning.
* **Metadata Enrichment:** Tags chunks with Source URL, sequence number, and title.
* **Token Counting:** Uses `tiktoken` for precise context window management.

### ğŸ§  AI & Vectors
* **Embeddings:** Uses **Jina AI** (768 dimensions) for fast, free, and accurate vectorization.
* **Vector Database:** **Pinecone** for storage, similarity search, and metadata filtering.
* **LLM Integration:** **Google Gemini Flash** for high-speed, context-aware answers.

---

## ğŸ— Project Structure

```text
backend/
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ crawler/
â”‚   â”‚   |â”€ crawl.js              # BFS Crawler logic
|   |   |â”€ exract.js
|   |   |_utils.js
â”‚   â”‚
â”‚   â”œâ”€ processing/
â”‚   â”‚   â”œâ”€ chunker.js            # Text splitting & token counting
â”‚   â”‚   â””â”€ embedder.js           # Jina AI integration
â”‚   â”‚
â”‚   â”œâ”€ db/
â”‚   â”‚   â”œâ”€ pinecone.js           # DB Configuration
â”‚   â”‚   â”œâ”€ storeVectors.js       # Upsert logic
â”‚   â”‚   â””â”€ queryVectors.js       # Similarity search
â”‚   â”‚
â”‚   â”œâ”€ utils/
â”‚   â”‚   â””â”€ processCrawledPages.js # Pipeline orchestration
â”‚   â”‚
â”‚   â”œâ”€ controllers/
â”‚   â”‚   â”œâ”€ crawlController.js
â”‚   â”‚   â””â”€ ragController.js
â”‚   â”‚
â”‚   â”œâ”€ routes/
â”‚   â”‚   â”œâ”€ crawlRoutes.js
â”‚   â”‚   â””â”€ ragRoutes.js
â”‚   â”‚
â”‚   â””â”€ server.js                  # Entry point
â”‚
â”œâ”€ package.json
â””â”€ .env
```

---

## ğŸ“¦ Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone [https://github.com/NishantTripathi21/VectorCrawl-Engine](https://github.com/NishantTripathi21/VectorCrawl-Engine)
cd VectorCrawl-Engine/backend
```

### 2ï¸âƒ£ Install dependencies
```bash
npm install
```

### 3ï¸âƒ£ Configure Environment Variables
Create a `.env` file in the `backend` folder and add your API keys:

```env
# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_key
PINECONE_INDEX=rag-search

# Jina AI (Embeddings)
JINA_API_KEY=your_jina_key

# Google Gemini (LLM)
GEMINI_API_KEY=your_gemini_api_key
```

### 4ï¸âƒ£ Run the Backend
```bash
node src/server.js
```
*Server runs on: `http://localhost:3000`*

---

## ğŸ§  API Endpoints

### 1ï¸âƒ£ Start Crawling
**POST** `/api/crawl/start`

Initiates the crawling and embedding pipeline for a specific URL.

**Body:**
```json
{
  "url": "[https://example.com](https://example.com)"
}
```

**Response:**
```json
{
  "success": true,
  "pagesCrawled": 5,
  "chunksCreated": 120,
  "vectorsStored": 120
}
```

### 2ï¸âƒ£ Ask a Question (RAG)
**POST** `/api/rag/ask`

Retrieves relevant context and generates an answer.

**Body:**
```json
{
  "question": "What services does this website offer?"
}
```

**Response:**
```json
{
  "success": true,
  "answer": "Based on the website content, they offer...",
  "contextUsed": 3
}
```

---

## ğŸ”„ The RAG Pipeline (Under the Hood)

1.  **Crawl & Extract:**
    * Normalize URLs.
    * Extract raw text using `Cheerio`.
2.  **Chunking:**
    * Split text into 500-1000 token chunks.
    * Attach metadata (URL, Page Title).
3.  **Embedding:**
    * Convert text chunks to vectors using `jina-embeddings-v2-base-en`.
4.  **Storage:**
    * Upsert vectors to Pinecone.
5.  **Retrieval:**
    * User asks a question â†’ Convert question to vector.
    * Query Pinecone for top-k similar chunks.
6.  **Generation:**
    * Feed `Context + Question` to **Gemini Flash**.
    * Gemini generates an answer based strictly on the context.

---

## ğŸ“˜ Future Improvements
- [ ] **Real-time Updates:** Implement Server-Sent Events (SSE) for crawling progress.
- [ ] **Multi-Tenancy:** Support multiple users with separate vector namespaces.
- [ ] **Frontend:** Build a Next.js UI for the chat interface.
- [ ] **Job Queue:** Use BullMQ to handle large crawling jobs in the background.

---

## ğŸ’¡ Key Skills Demonstrated
This project highlights competency in:
* **LLM Integration & RAG Architecture:** Building industry-standard AI pipelines.
* **Vector Search:** Implementing semantic search using Embeddings and Pinecone.
* **Backend Engineering:** Scalable Node.js architecture with separation of concerns.
* **Data Engineering:** Web crawling, data cleaning, and unstructured data processing.

---

## ğŸ‘¨â€ğŸ’» Author

**Nishant Tripathi**
* **B.Tech CSE, NIT Srinagar**
* *Role:* â€¢ Full Stack Developer â€¢ GenAI â€¢ Cloud 

[GitHub](https://github.com/NishantTripathi21) | [LinkedIn](https://linkedin.com/in/nishanttripathi21)